---
title: "Estero La Cruz Guild Analysis"
author: "Pava Francisca Ellison Gonzalez"
date: "12/5/2020"
output:
  html_document: 
    fig_width: 8
    highlight: breezedark
    theme: cosmo
    toc: yes
    toc_float: yes
---

# Preface

In this document, we'll go through the many many different steps I've taken in an attempt to analyze several years of waterbird surveys at Estero La Cruz in Bahía de Kino, Sonora. Rather than only include the final model and results, I started this document when I began working with the data-- so this document has evolved and grown alongside me as I worked through the various problems/errors/roadbloacks I encountered. While initally working with the data, I tried to use multiple variables to take advantage of the various data we collect at each survey. However, I've learned a lot about modeling and ultimately found myself following the advice to keep it all as simple as possible. By the end of this document, you'll see that a lot of time and effort has been put into this to address a simple question- Has the number of shorebirds at Estero La Cruz changed over time? 

```{r set up, echo=FALSE, message=FALSE}
library(knitr)
opts_chunk$set(echo = TRUE)
```

# Los Datos

The first steps are loading all required packages and of course---the data. This may seem like a long list of packages, but I've only added in the important ones that I know are being applied. Any additional packages that those on this list are dependent upon will also be loaded. 

```{r pkgs, message=FALSE, warning=FALSE}
library(dplyr)
library(ggplot2); theme_set(theme_linedraw())
library(ggpubr)
library(ggeffects)
library(gridExtra)
library(stringr)
library(lme4)
library(MASS)
library(stringr)
library(lubridate)
library(tidyr)
library(readr)
library(RColorBrewer)
library(MuMIn)
library(patchwork)
library(pscl)
library(StatisticalModels)
library(numDeriv)
library(multcomp)
library(AICcmodavg)
library(sjPlot)
```

All the necessary files should be saved in the working directory. 
The files we'll Counts of birds in each guild for each survey at Estero La Cruz from 2013/14 to present cycle and these are "environment variables" taken at each survey. Similar to the biodiversity 

***Don't forget to change the path OR make sure the files are in your working directory***

```{r import data}
guild_totals <- read_csv("guild.totals.csv",
                         col_types = cols(Date = col_date(format = "%m/%d/%y")))

enviro <- read_csv("current_enviro.csv",
                   col_types = cols(Date = col_date(format = "%m/%d/%y")),
                   na = "0")
```

Here's a sneak peak of the data--as you can see it's set up with each survey effort as a row with every guild as a column. 
`r kable(guild_totals[1:5, 1:5], caption = "Preview of Guild Totals")`

Next, we'll do a bit of cleaning of the data. To up the environmental variables, we'll parse out the "tide" variable into "tide_height" and "tide_dir". This pipe code comes from the code Abram sent me.

```{r clean data, message=FALSE, warning=FALSE}
enviro_clean <- enviro %>%
  mutate(tide_height=str_extract(Tide,"mid|low|high|Mid|Low|High"),
         tide_height=ifelse(is.na(tide_height),"unk",tide_height),
         tide_height=tolower(tide_height),
         tide_dir=str_extract(Tide,"slack|rising|falling"),
         tide_dir=ifelse(is.na(tide_dir),"slack",tide_dir))

##pull out the enviroment factors/variable
a <- enviro_clean[,3:11]

##pull out data/time to potentially use
date.1 <- guild_totals$Date
mes <- format.Date(date.1, "%m")
mes <- as.double(mes)
mes.yr <- format.Date(date.1,"%m/%y")

##bring it all together into the same data frame
guild_totals <- cbind(guild_totals, a)
guild_totals <- cbind(guild_totals, mes)
guild_totals <- cbind(guild_totals, mes.yr)

##now remove "summer" data because sampling isn't consistent 
guild_totals <- filter(guild_totals, szn != "4")

##later there are some problems because it's an interger
##so i made it a double instead of a factor
guild_totals$Temp <- as.double(guild_totals$Temp)
guild_totals$mes <- as.double(guild_totals$mes)
```

# Preliminary Plots

To start, I made some boxplots to at each of the guilds, grouped by field season (temporada) and season (estación):

Also, some background- I have divided the seasons as 1-Fall 2-Winter 3-Spring---these seasons were decided as how to split the data because of migration. Someone had suggested maybe grouping fall and spring (again because migration) and later I end up doing it. In my efforts of working/testing/exploring models, it became apparent that springs and fall were pretty consistently similar enough that later, I did end of grouping them.

Note that in the data the variable "temporada" is actually the field season that runs fall-summer. So "20" is the fall 2019-present, "19" is fall 2018-spring 2019, etc.

```{r box plots of data, echo=FALSE, fig.height=5, fig.width=8}
shore <- ggboxplot(guild_totals, x = "temporada", y = "shore", facet.by = "szn",
          panel.labs = list(szn=c("Otoño", "Invierno", "Primavera")),
          title = "Shorebirds", ylab = "Count", ggtheme = theme_linedraw())

gulls.terns <- ggboxplot(guild_totals, x = "temporada", y = "gulls_terns", facet.by = "szn", 
                panel.labs = list(szn=c("Otoño", "Invierno", "Primavera")),
                title = "Gulls/Terns/Skimmer", ylab = "Count", ggtheme = theme_linedraw())

pel.corm <- ggboxplot(guild_totals, x = "temporada", y = "pel_corm", facet.by = "szn", 
                         panel.labs = list(szn=c("Otoño", "Invierno", "Primavera")),
                         title = "Pelicans/Cormorants", ylab = "Count", ggtheme = theme_linedraw())

land <- ggboxplot(guild_totals, x = "temporada", y = "land", facet.by = "szn", 
                  panel.labs = list(szn=c("Otoño", "Invierno", "Primavera")),
                  title = "Landbirds", ylab = "Count", ggtheme = theme_linedraw())

waders <- ggboxplot(guild_totals, x = "temporada", y = "waders", facet.by = "szn", 
                    panel.labs = list(szn=c("Otoño", "Invierno", "Primavera")),
                    title = "Waders", ylab = "Count", ggtheme = theme_linedraw())

water <- ggboxplot(guild_totals, x = "temporada", y = "waterfowl", facet.by = "szn", 
                   panel.labs = list(szn=c("Otoño", "Invierno", "Primavera")), 
                   title = "Waterfowl", ylab = "Count", ggtheme = theme_linedraw())
shore 
gulls.terns
pel.corm
land
waders
water
```


# Initial Shorebird Abundance Modeling 

Here is some of my initial messy exploration/attempts at modeling to look for trends/changes in shorebird abundance over time. Because we're working with count data, I started with a Poisson distribution. From what I've read, I found that overdispersion is a common problem when modeling count data so I kept that in mind.

```{r pois glm}
shore_pois_mod <- glm(shore~temporada+szn+mes+Temp+tide_height+tide_dir,
                       data=guild_totals, family = poisson)

##one way to check for overdispersion is to run a chi-squared
pchisq(summary(shore_pois_mod)$deviance, summary(shore_pois_mod)$df.residual)

##or you can just divide the deviance of the residuals by df residuals
(shore_pois_mod$deviance)/((shore_pois_mod)$df.residual)

```

So both should be close to 1. Not 1 or 309... 
Our output of 309 means there is a lot of overdispersion in the model, or that there is a lot of variation unaccountated for through the model. This is because in a poisson distribution the mean and the variance are supposed to be equal. Overdispersion means that the variance is much greater than the mean.   
So next I tried to simplify the model and look just at seasonality...

```{r simplified pois glm}
shore_pois_mod1 <- glm(shore~szn, data=guild_totals, family = poisson(link="log"))
summary(shore_pois_mod1)
pchisq(summary(shore_pois_mod1)$deviance, summary(shore_pois_mod1)$df.residual)
```

Clearly, still dealing with some overdispersion problems so next I tried running a glm but this time with a quasipoisson distribution.

```{r qpois glm}
shore_qpois_mod <- glm(shore~szn+Temp+mes, data=guild_totals, family = quasipoisson)
summary(shore_qpois_mod)
(shore_qpois_mod)$deviance/(shore_qpois_mod)$df.residual
```

Once again, I'm stll having problems with the model being quite overdispersed. So next I tried a negative binomial model.

```{r nb glm}
shore_nb_mod <- glm.nb(shore~szn+Temp+mes+tide_height+tide_dir, data=guild_totals, link = "log")
summary(shore_nb_mod)
(shore_nb_mod)$deviance/(shore_nb_mod)$df.residual
```

This is looking a lot better, and actually there is no longer the very high degree of overdispersion which is great. Looking back on 
So lets check the residuals real quick:

```{r nb resids, fig.height=8, fig.width=8, echo=FALSE}
par(mfrow=c(2,2))
plot(shore_nb_mod)
```

Not too terrible...
From these plots of the residuals, there is a bit of a pattern to them, as well as a few data points that jump out (30 and 47). Though it does raise some flags, it looks decent. But rather than being satisfied with this, I kept exploring. 

## Tansforming the data 

A zero-inflated model seemingly is another route to go, but that wouldn't work or make any sense at all given I don't have any zeros in this data. Though there are varying opinions for and against it, I thought maybe I should try transforming the data. This seems like a valid thing to given the lack of zeros in this data and that seemed to be one big argument against transforming the data. I checked it out, knowing this might work with the shorbird guild. While some of the other surveys of guilds do have zeros, from my understanding there is not an amount that might call for a zero-inflated or truncated poisson model. But that might be a later conversation with a statistician. 

```{r transforming data}
##quick check of the distribution
hist(guild_totals$shore)
##and the log transformed data
hist(log(guild_totals$shore))
```

Given the data looks a lot closer to a normal distribution, I decided to see what would happen if I tried running the models with transformed data. So I tried just a classic gaussian distribution glm.

```{r glm log shoreb}
logshore_mod <- glm(log(shore)~temporada+szn+mes+Temp+tide_height+tide_dir, data=guild_totals)
summary(logshore_mod)
pchisq(summary(logshore_mod)$deviance, summary(logshore_mod)$df.residual)
```

This is also looking pretty decent and lke a potential route to follow. And it might be better because I'll get lower AICc values but I'm not sure if I'll be able to replicate this with the other guilds. And now let's check out the residuals:

```{r check log resids, fig.height=8, fig.width=8, echo=FALSE}
par(mfrow=c(2,2))
##graph default plots
plot(logshore_mod)
```

Again, two data points are jumping out of the data (37 and 57)....so gonna take a look at the data...
Let's see if the data is actually distributed normally by running a Shapiro-Wilk Normality test. 

```{r test norm, echo=FALSE, message=TRUE}
##first lets check the raw data
shapiro.test(guild_totals$shore)
```

YIKES. 
Now lets check the log-transformed data. 

```{r other norm test, echo=FALSE, message=TRUE}
shapiro.test(log(guild_totals$shore))
```

Ok so that's also not dristributed normally. Soo with some fresh thoughts, I went to maybe trying to use monthly means. 

## Using Monthly Means?

I calculated the mean number of shorebirds per month for each year. This might work because there are typically two surveys per month. But one reason it might is every number will end with .5 or an interger. 

```{r means, warning=FALSE}
##calc mean # of shorebirds per month for each year 
##recall that mes.yr was date formated as "%m/%y"
##so I used that to calculate the means
shore.mean <- aggregate(shore ~ mes.yr, guild_totals, FUN=mean)

##wrote the output into a csv because it seemed easier to combine 
write_csv(shore.mean, "shoremeans.csv")
write_csv(enviro_clean, "cleanedenviro.csv")

##then I did the same thing with the "avg temp" per month for each year
##NOTE: still waiting on the CICESE data...
options(na.action = "na.omit")
temp.mn <- aggregate(Temp ~ mes.yr, guild_totals, FUN=mean)
write_csv(temp.mn, "tempmean.csv")

##combined data outside in excel--oooops--and then brough it back in
shoremeans <- read_csv("shoremeans.full.csv")

##instead of opening the whole data frame, just check the column names
##quick way to cheat and see the variables
colnames(shoremeans)
```

So next I ran some glms wth these means.

```{r mean glms}
##check distribution of data real quick
hist(shoremeans$shore)

##gaussian
summary(glm(shore~mes+ciclo+szn+temp, data=shoremeans))
```

This model is looking like a pretty poor fit. My thought is that because even though now we are working with means, the data is still mostly integers.
So I tried the same thing, but with a gamma distribution, mostly because it's a different distribution.

```{r mn gamma glm}
summary(glm(shore~mes+ciclo+szn+temp, data=shoremeans, family = Gamma))
```

Ok ok looking better but this can maybe be cleaner. So I tried transforming the means and doing it again. First I tried square-root transformation. 

```{r means sqrt transformed}
hist(sqrt(shore.mean$shore))

##decided to play with it a bit since the data is distributed better when transformed
summary(glm(sqrt(shore)~ciclo+szn+temp, data=shoremeans))
```

This doesn't look great- just look at the deviance. So then I tried a log transformation.

```{r means log transformed}
##log-transformed
hist(log(shore.mean$shore))

summary(glm(log(shore)~ciclo+szn+temp+mes, data=shoremeans))
```
Also, I went back to the begining of Abram's "glm_esteros" code and saw the gamma distribution glm. So I tried that and got some surprising results. Will may bring that into all this later. And actually this is looking pretty decent. So lets take a quick look at the residuals.  

```{r means log transformed-resids, fig.height=8, fig.width=8, echo=FALSE}
par(mfrow=c(2,2))
plot(glm(log(shore)~ciclo+szn+temp+mes, data=shoremeans))
```

Just from the residuals, definitely looks like there are some patterns in there- soooo maybe not the best fit, even if some of the other parts of modeling are seemingly working out better. Plus, the qq-plot isn't too convincing. 

## Model Selection

Great so we've got some models, Maybe they aren't the best but it's what I have to work with so far. Now we need to select and compare them. One way is to use inforation criteria such as the AICc. 
But there are also some neat ways to automate it. At the end of Abram's code, I found the function dredge() so I looked into it. Here I'm using the "shoremeans" file I just created above.  

```{r model comparison}
##one way to calculate the AICc
AICc(glm(log(shore)~szn+temp+mes, data=shoremeans))
##but this just spits out the calculated AICc from a given model
##this is cool but we can do better to select a model...

##first I saved the model with the log-transformed mean data
log.mod <- (glm(log(shore)~ciclo+temp+szn+mes, data=shoremeans)) 
```
  
This new model is the same as performed above whose residuals are shown. So now that we have the model saved, we can use the `dredge()` function to get a model selection table. When I was initially running the function, I got some errors. With help of interwebs and `help()`, I realized that I needed to change the way R deals with NA values. So before using that function, make sure the code `options(na.action = "na.fail")` runs---or else you'll get an errror.

```{r automating it w/ dredge}
options(na.action = "na.fail") ##handling NA values

d1 <- dredge(log.mod, extra = "R^2") ##you can also add extras like R^2 values
subset(d1, delta < 5)
```

Pretty neat. 
Now let's save another model that we had check earlier-- the gamma distribution. Feel free to scroll up to check the output of the model. 

```{r mn gamma mod dredge, warnings=FALSE, message=FALSE}
shoremn.mod <- glm(shore~szn+temp+mes+ciclo,data=shoremeans, family = Gamma)
mod_mn_dredge<-dredge(shoremn.mod, extra = "R^2")
subset(mod_mn_dredge, delta < 3)
```

The `dredge()` function works with various types of model. For example, it will also work with negative binomial glms, so here we'll use the `shore_nb_mod` from earlier--aka one of the models whose residuals were graphed above.

```{r shore nb glmer dredge, warnings=FALSE, message=FALSE}
shore_nb_mod

##now the magic
mod_nb_dredge<-dredge(shore_nb_mod,extra = "R^2")
subset(mod_nb_dredge, delta < 4)

##from the same package, you can also do some model averaging 
summary(model.avg(mod_nb_dredge, subset = delta <4))
```

In the code above, I turned off the warning messages as many warning messages as I was finding out that negative binomal models can be a bit tricky to work with. 
Ok this was cool and some good practice in modeling, but I still hadn't necessarily found the best way to model my data that stays true to the biology. 
**And thus I entered...**

# The World of GLMERs

***EXLPAIN AND DESCRIBE MODELS BETTEER TO EXPLAIN WHAT THE EFFECTS ARE***

I started playing with the idea of mixed models because they are a common tool used in biological modeling. Given the data we're wworking with and question we're trying to answer, the random effect that needs to be taken into account with this modeling is the observer(s). With several years of data and different people counting birds over the years, that's probably one of the biggest sources of variation in the data---and hence random effect of the observer(s)!! 

```{r glmers, warning=FALSE, message=FALSE}
options(na.action = "na.omit")
##add in the year/cycle as a factor
guild_totals$ciclo <- as.factor(guild_totals$temporada)
##another way to do this would be to write factor(temporada) in the formula
##but I just added it in here since it was easier

glmer.s <- glmer(shore ~ temporada + szn + tide_height + tide_dir + 
                   mes + (1 | obs),data = guild_totals,family="poisson")
glmer.s1 <- glmer(shore ~ ciclo + szn + tide_height + tide_dir + 
                    mes + (1 | obs),data = guild_totals, family="poisson")
```

I removed warnings and messages from above to save some space. But what I can tell you is there are pretty trash models, regardless of whether or not the cycle is a read as a factor or a continuous vaariable. I was testing the model in this way because I was unsure of how year should be read. I've determined that in this, I'm not trying to compare each year to one another but rather look for an overall trend over time. 

Singluarity, convergence, and just lots of problems and headaches that can be avoided. What I've done to troubleshoot is going into some different directions. Just for shits and giggles though, let's go ahead and run a quick line to see how the automated model selection might pick the best model. 

```{r poop, echo=FALSE}
options(na.action = "na.fail")
```

```{r glmer dredge, warning=FALSE, message=FALSE}
glmer.dd <- dredge(glmer.s1)
subset(glmer.dd, delta < 5)
```

This is still a bit of a headache. But thats ok. Just as a refresher so far I've tried GLMs of all sorts (poisson, quasipoisson, negative binomials, log-transformed gaussian) and now we've added a poisson GLMER. 
Since working with the data thus far has seemed to best fit the negative binomial distribution, lets used that in our mixed model. 

```{r poop 2, echo=FALSE}
options(na.action = "na.omit")
guild_totals$season <- as.character(guild_totals$szn)
guild_totals$ciclo <- as.character(guild_totals$temporada)
```

```{r final shore nb glmer}
glmernb.shore1 <- glmer.nb(shore ~ temporada + season + (1|obs), data=guild_totals)
summary(glmernb.shore1)
GLMEROverdispersion(glmernb.shore1)
```

Alright- it looks like we aren't dealing with an absurd amount of overdispersion that was previously a problem. 

## Residuals

Now let's take a look at 'em. 
```{r nb glmer resids, fig.height=8, fig.width=8, echo=TRUE}
##put all the imporant things into a data frame
resid_shore1<-data.frame(
    pearsons_residuals=resid(glmernb.shore1,type="pearson"),
    deviance_residuals=resid(glmernb.shore1,type="deviance"),
    response_residuals=guild_totals$shore-predict(glmernb.shore1,type = "response"),
    predicted=predict(glmernb.shore1,type = "response"),
    observed=guild_totals$shore)

##plot predictions and resids
ggplot(resid_shore1,aes(x=predicted,y=pearsons_residuals))+
  geom_point() +
  ggplot(resid_shore1,aes(x=predicted,y=deviance_residuals))+
  geom_point()+
  ggplot(resid_shore1,aes(x=predicted,y=response_residuals))+
  geom_point()+
  ggplot(resid_shore1,aes(x=predicted,y=observed))+ geom_point()
```

*Also note that that code for these plots was more or less copy/pasted from Abram's code*

Similar to previous models, this isn't necessarily the best looking set of residual graphs, but for now we can work with it.

## Combining Migration Seaons??

I have only begun looking into the world of testing models and hypotheses. One method I encountered to test general hypotheses was an example I found on the internet proved useful. Essentially what I was interested in testing was whether or not there are differences between the seasons. This sets up a pairwise comparison between factors using a Tukey test. 

```{r hypothesis test}
posthoc1 <- glht(glmernb.shore1, linfct = mcp(season="Tukey"))
mcs <- summary(posthoc1, test=adjusted("single-step"))
mcs     ##call it to look at the pairwise comparison 
```

This is pretty neat. It shows which factors are siginificantly different from one another and which are similar enough to be the same. 
Since there are only 3 factors in the variable of season, the output is pretty small and easy to read. But imagine if there were 10 different factors of the variable? Could get pretty messy pretty quickly---so another way to look at each factor is to use letters. This is easier to follow and thus more accessible to interpret determine whether factors were similar or significantly different. 

```{r letters of hyp test}
cld(mcs, level=0.05, decreasing=TRUE)   ##cld = compact letter display
```

So what all that means is that spring and fall are similar to one another (hence the same letter) but winter is different. This makes sense given there is an influx of migrants in the winter and birds similarly moving through or completely absent in the fall and spring. In the OG data, 1=fall, 2=winter, 3=spring. Below I'll change the data so that fall/spring=1 and keep 2=winter using a simple `ifelse()` command. 

```{r combine seasons}
guild_totals$season <- ifelse(guild_totals$season != 2, 1, 2)
guild_totals$season <- as.factor(guild_totals$season)
```

Now that the data is combined, let's take a new look at it. Here I used more or less the same code as the boxplots at the beginning of the document. 

```{r combined szn plots, echo=FALSE}
shore1 <- ggboxplot(guild_totals, x = "temporada", y = "shore", facet.by = "season",
          panel.labs = list(season=c("Otoño/Primavera", "Invierno")),
          ylab = "Shorebird Count", ggtheme = theme_linedraw())
shore1
```

And just a refresher/overview, let's look at the data, but rather than being divided by season, it is only divided by the work cycle/year ("temporada"). 

```{r og data}
sb <- ggplot(guild_totals, aes(factor(temporada), shore, group=temporada))
sb + geom_boxplot() + labs(title = "Shorebird Counts by Season") +
  theme(plot.title = element_text(hjust = 0.5))
```


# Final Model Selection and Interpretation

Since I haven't been able to get the automated model selection `dredge()` to work with the negative binomial glmer, there are some other ways to do what I want to do and compare the models. It's not quite as pretty but as far as I understand model selection, it makes sense.
First we'll make a null model and go through some steps to change/add variables to our models.

```{r shorenb model final final}
null.shore <- glmer.nb(shore ~ 1 + (1|obs), data=guild_totals)

##and start with a simple model containing what we want to test
glmernb.shore1 <- glmer.nb(shore ~ temporada + season + (1|obs), data=guild_totals)
summary(glmernb.shore1)
```

Just from an intial look at this model summary, it looks like there is a significant decline in the abundance of shorebirds over time. It also appears, as expected, that there is a significant increase in in the winter months when compared to the rest of the year. Before we saying anything more, let's do a handful of other steps to check the model and make sure this will be our final model.

```{r overdisp and anova}
GLMEROverdispersion(glmernb.shore1)
##now let's compare it with the null by making an ANOVA table
anova(null.shore, glmernb.shore1)
```

Since there is a significant difference, this means we can reject the null model and accept the simple negative binomial mixed model as a betterr fit to the data. I also feel OK about that given the AICc/BIC are slightly lower, and the log-Liklihood has moved a bit closer to 0 (which is another one of many things to look for). 

## Selecting a Model

There are a wide variety of criteria and methods that are used to select models. Here, I go through a few different 
Now let's add in some other potential variables that would affect the presence of birds, in this case, the tide!

```{r more models for comp}
##add tide height?
glmernb.shore2 <- glmer.nb(shore ~ temporada + season + tide_height + (1|obs), 
                           data=guild_totals)
##add tide dir?
glmernb.shore3 <- glmer.nb(shore ~ temporada + season + tide_dir + (1|obs), 
                           data=guild_totals)
##add both tide variables?
glmernb.shore4 <- glmer.nb(shore ~ temporada + season + tide_height + tide_dir +
                             (1|obs), data=guild_totals)
```

We can make a neat model selection table based on information selection criteria. Here we will use the second order AIC (AICc) for comparison. For the model names, I abbreviated the names into "modX" so note that "mod1" = "glmernb.shore1", "mod2" = "glmernb.shore2", etc...

```{r aicc model table}
shore.cand <- list(null.shore, glmernb.shore1, glmernb.shore2, glmernb.shore3, glmernb.shore4)
mod.names <- list(c("null", "mod1", "mod2", "mod3","mod4"))
aictab(shore.cand, mod.names)       ##this exports our pretty html table below
```

Let's do another check by comparing increasingly complex models using ANOVAs. If the Chi-squared value is significant, that means that the model is a better fit. 
We will set up comparisons between our simplest model (glmernb.shore1) and each of the increasingly complex models. While we can use the code to set up single comparisons between models (ie. `anova(mod1, mod2)`) we can also combine it into one line of code such as `anova(mod1, mod2, mod3, ...)` and we will get a table that compares our simplest model (mod1) with the rest of the models. 

`r kable(anova(glmernb.shore1, glmernb.shore2, glmernb.shore3, glmernb.shore4))`

What each of these show, is that with adding in the height and/or direction of the tide, we do not get a better fitting model. That means we should stick to the first (and most simple!) model as is the best fit. 

Another potential approach to model selection would be to average the models. But rather than follow more coomplicated steps to do that, I think it's OK to stick with this process of selecting the best model

## Calculating R^2

Now that we have selected a model, one interesting piece of information about the model is checking the R^2 value. While this measure is commonly used in lms and glms it can be applied to mixed models. Here the function will calculate the R^2 values taking into account only the fixed effects (marginal) as well as all effects (conditionall) using 3 different methods.
Here's the explanataion taken from the `help("r.squaredGLMM")`: 

> Marginal R_GLMM² represents the variance explained by the fixed effects, and is defined as: $$R_GLMM(m)² = (σ_f²) / (σ_f² + σ_α² + σ_ε²)$$ 
Conditional R_GLMM² is interpreted as a variance explained by the entire model, including both fixed and random effects, and is calculated according to the equation: $$R_GLMM(c)² = (σ_f² + σ_α²) / (σ_f² + σ_α² + σ_ε²)$$ where σ_f² is the variance of the fixed effect components, σ_α² is the variance of the random effects, and σ_ε² is the “observation-level” variance.

So with that we can make a table of these values:
```{r r^2 shore mod, warning=FALSE}
(r.squaredGLMM(glmernb.shore1))
```

From the this, it looks like our model does a pretty decent job of fitting the data and explaining the variance. Given we're modeling change over time and not taking into account other environmental variables that are likely affecting the presence/absence/abundance of birds, I feel okay about believing this model. 

## Check Residuals

We'll run more or less the same code as we used above. See the .rmd file for code.
Recall that the difference now is that 

```{r final nb glmer resids, fig.height=8, fig.width=8, echo=FALSE}
##put all the imporant things into a data frame
resid_shore2<-data.frame(
    pearsons_residuals=resid(glmernb.shore1,type="pearson"),
    deviance_residuals=resid(glmernb.shore1,type="deviance"),
    response_residuals=guild_totals$shore-predict(glmernb.shore1,type = "response"),
    predicted=predict(glmernb.shore1,type = "response"),
    observed=guild_totals$shore)

##plot resids and all that jazz
pr <- ggplot(resid_shore2,aes(x=predicted,y=pearsons_residuals)) + geom_point()
dr <- ggplot(resid_shore2,aes(x=predicted,y=deviance_residuals)) + geom_point()
rr <- ggplot(resid_shore2,aes(x=predicted,y=response_residuals)) + geom_point()
po <- ggplot(resid_shore2,aes(x=predicted,y=observed)) + geom_point()
grid.arrange(pr, dr, rr, po)
```

Again, it looks more or less the same as before. Our residuals aren't perfectly randomly distributed but I'm not sure what I could do at this point to get a better fit. Given the process to get to this model, I think it's acceptable for the sake of this analysis. 

## Plotting Model Predictions

Now it's time to look at our model predictions. One of the most important aspects of a regression are the estimates of each variable in the model. Since we're working with negative binomial models, there is a log link meaning the effect estimates need to be log transformed. We can do that easily by using R as a fancy calculator. Before we do that, let's take a quick look at the different estimates of the model. 

```{r shore estimates graph, echo=FALSE}
tmp <- as.data.frame(confint(glht(glmernb.shore1))$confint)
tmp$Comparison <- rownames(tmp)
ggplot(tmp, aes(x = Comparison, y = Estimate, ymin = lwr, ymax = upr)) +
  geom_errorbar() + geom_point()
```

The first thing you might notice is that the intercept is very high- yes but it's not as important. If we think about the data we're modeling, there are counts of shorebirds in the thousands, and in the first year of data (2013-2014 season), there is a very high degree of variability.  
What we really want to pay more attention to are the estimates of two fixed effects of the model. Just by looking at this grarph, the effect of season is a positive increase while that of temporada(which is the year/cycle) is negative.  
If you recall from the summary output of the model the estimate of the variable temporada was: `r tmp$Estimate[2]`. To translate that into normal terms, as the year/cycle changes by 1, the change in shorebird abundance is multipled by a factor of `r exp(-0.21397)`. This can be interpreted into that "the abundance of shorebirds is declining by `r (1-exp(-0.21397))*100`% each year." 
One way we can visualize this is by plotting the predicted values on a graph. We can plot the overall trend of the model. Note that this will back-transform the predicted values to the original scale of our response variable.  

```{r main pred graph group, echo=FALSE}
pred1 <- ggpredict(glmernb.shore1, c("temporada"))
plot(pred1)
```

However, we know there are differences between the season and that there was a significant effect in the model. From the model estimate of that variable, we can say winter season sees an increase of `r exp(tmp$Estimate[3])*100`% in the number of shorebirds in comparison to the rest of the year. 
Knowing that the difference is so great, let's take a look at the same graph as above, but grouped by season. 
*Recall that the seasons are split into 1: Fall/Sping and 2: Winter.*

```{r shore pred graph, echo=FALSE}
pr1 <- ggpredict(glmernb.shore1, c("temporada", "season"))
plot(pr1, colors="ipsum")
##pick one
pd <- position_dodge(width=0.4) 
gg.s1 <- ggplot(pr1, aes(x, predicted, colour = group)) + scale_color_manual(values = c("#3f2d54", "#75b8d1"))
gg.s1 + geom_point(position = position_dodge(.3)) + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), position = pd) 
```
    
*Note that both graphs above are the same data, just plotted differently.*    
 
In both graphs, the seasons are split into 1 (Fall/Sping--the migration seasons) in purple and 2 (Winter) in blue. These colors will be consistent throughout the rest of this document. 
This shows that while shorebird abundance is declining in both seasons, it's clear that the decline is more pronounced in the winter-we can visually see this as the slope of the line is steeper. This could potentially be due a decline in the migratory species overwintering, so it would be a good idea to look further into the migratory species.

Plot the random effects. 
And also a diagnostic plot:
> For **generalized linear mixed models**, returns the QQ-plot for random effects.   

So diagnostic plot is essentially just a qq plot

```{r more}
set_theme(base = theme_linedraw())
plot_model(glmernb.shore1, type="re", colors = "ipsum", vline.color = "red")
plot_model(glmernb.shore1, type="diag")
```

The first plot shows the random effects. The red line indicates no effect. The blue indicates a positive effect while purple is negtative. 
The second plot above, as mentioned, is a qqplot. 

```{r más}
##show it as connected line
shore_resids <- cbind(resid_shore2, guild_totals$season)
shore_resids <- cbind(shore_resids, guild_totals$temporada)
shore_resids$temporada <- shore_resids$`guild_totals$temporada`
shore_resids$season <- shore_resids$`guild_totals$season`
shore_resids$szn <- as.factor(shore_resids$`guild_totals$season`)

ggplot(shore_resids, aes(guild_totals$temporada, predicted, colour = szn)) + 
  stat_summary(geom="smooth", fun.data=mean_cl_normal, width=0.1, conf.int=0.95) +
  stat_summary(geom="line", fun=mean, linetype="dashed") +
  stat_summary(geom="point", fun=mean) 
```


# Convergence Problem Troubleshooting

Both during my model exploration with shorebirds as well as with other guilds, I ran into a handful of problems. One common problem I ran into was a failure for the model to converge. This convergence failure essentially means that the model fits the data extremely poorly, or the observations just don't match up. But this isn't the end of the world. For example, when I tried to apply a negative binomial mixed model to the waterfowl guild data, I ran into this problem. Below is an example of how I handled it.

```{r poop 3, echo=FALSE}
options(na.action = "na.omit")
```

```{r fowl}
##now the other guilds. #this outputs a lot of warnings and it isn't goood 
glmernb.fowl1 <- glmer.nb(waterfowl ~ temporada + season + (1|obs), data=guild_totals)
summary(glmernb.fowl1)
```

Luckily, I found this [neat guide](https://rstudio-pubs-static.s3.amazonaws.com/33653_57fc7b8e5d484c909b615d8633c01d51.html) that I followed and found helpful. Below I follow the steps of the aformentioned guide and fix the problem. What the steps below basically do is try to optimize the model, starting from the inital fit but increasing the number of iterations. 

```{r convergence problems}
tt <- getME(glmernb.fowl1,"theta")
ll <- getME(glmernb.fowl1,"lower")
min(tt[ll==0])

derivs1 <- glmernb.fowl1@optinfo$derivs
sc_grad1 <- with(derivs1, solve(Hessian,gradient))
max(abs(sc_grad1))

max(pmin(abs(sc_grad1),abs(derivs1$gradient)))

ss <- getME(glmernb.fowl1,c("theta","fixef"))
glmernb.fowl2 <- update(glmernb.fowl1,start=ss,control=glmerControl(optCtrl=list(maxfun=2e4)))
```

No more failure to converge! So let's check for overdispersion and look at the summary output of the model.

```{r check model}
GLMEROverdispersion(glmernb.fowl2)
summary(glmernb.fowl2)
```
It looks like there is a significcant decline in the abundance of waterfowl over time. It also appears, as expected, that there is a significant increase in in the winter months in comparison to the rest of the year.  

# Final Results of Other Guilds

Below, I present mostly just the numbers from the other guilds. 

## Waterfowl
Since we just worked on the waterfowl model above, let's start there and begin by plottin the data. 
```{r plot fowl, echo=FALSE}
water1 <- ggboxplot(guild_totals, x = "temporada", y = "waterfowl", 
                   ylab = "Count", ggtheme = theme_linedraw())
water1
#labs(title="Count grouped by season") + theme(plot.title = element_text(hjust = 0.5))
water2 <- ggboxplot(guild_totals, x = "temporada", y = "waterfowl", facet.by = "season", 
                   panel.labs = list(season=c("Otoño/Primavera", "Invierno")), 
                   ylab = "Count", ggtheme = theme_linedraw())
water2
#labs(title="Count Divided by season") + theme(plot.title = element_text(hjust = 0.5))
```

Recall our model `glmernb.fowl2` from directly above.  
Similar to before, we can once again calculate the R^2 values. This time we'll show it in neat table. `r kable(r.squaredGLMM(glmernb.fowl2))`
Once again, it's looking like we've got a pretty decent looking model.  

Let's check the residuals
```{r fowl nb glmer resids, fig.height=8, fig.width=8, echo=FALSE}
##put all the imporant things into a data frame
resid_fowl<-data.frame(
    pearsons_residuals=resid(glmernb.fowl2,type="pearson"),
    deviance_residuals=resid(glmernb.fowl2,type="deviance"),
    response_residuals=guild_totals$waterfowl-predict(glmernb.fowl2,type = "response"),
    predicted=predict(glmernb.fowl2,type = "response"),
    observed=guild_totals$waterfowl)

##plot resids and all that jazz
pr.f <- ggplot(resid_fowl,aes(x=predicted,y=pearsons_residuals)) + geom_point()
dr.f <- ggplot(resid_fowl,aes(x=predicted,y=deviance_residuals)) + geom_point()
rr.f <- ggplot(resid_fowl,aes(x=predicted,y=response_residuals)) + geom_point()
po.f <- ggplot(resid_fowl,aes(x=predicted,y=observed)) + geom_point()
grid.arrange(pr.f, dr.f, rr.f, po.f)
```

And now let's look at the model predctions. Using the estimate of our model, we can say there has been a decline of `r (1-exp(-0.36894))*100`% over the seasons and an increase of `r (exp(1.29668)*100)`% in the winter. 

```{r fowl mod plots, echo=FALSE}
pr.fowl <- ggpredict(glmernb.fowl2, c("temporada", "season"))
plot(pr.fowl, colors="ipsum")

gg.f1 <- ggplot(pr.fowl, aes(x, predicted, color=group)) + scale_color_manual(values = c("#3f2d54", "#75b8d1"))
gg.f1 + geom_point(position=pd) + geom_errorbar(aes(ymin=conf.low,ymax=conf.high), 
                                                 position=pd) + 
  scale_x_continuous(breaks = 14:20) + labs(x = "Year", y= "Predicted Count")
```

Similar to the shorebirds, we can see a similar difference in that the decline seems much more stark in the winter.  

## Gulls/Terns/Skimmers

Check the data
```{r gull plot, echo=FALSE}
gulls.terns1 <- ggboxplot(guild_totals, x = "temporada", y = "gulls_terns",
                ylab = "Count", ggtheme = theme_linedraw())
gulls.terns1

gulls.terns2 <- ggboxplot(guild_totals, x = "temporada", y = "gulls_terns", 
                          facet.by = "season", 
                          panel.labs = list(season=c("Otoño/Primavera", "Invierno")),
                          ylab = "Count", ggtheme = theme_linedraw())
gulls.terns2
```

Make the model
```{r gulls/terns/allies}
glmernb.gulls <- glmer.nb(gulls_terns ~ temporada + season + (1|obs),
                          data=guild_totals)
summary(glmernb.gulls)
GLMEROverdispersion(glmernb.gulls)
```
Once again, it looks likee there is a significant decline in the abundance of gulls/terems/skimmers over time as well as a significant increease in the winter due to the influx of migrants. 
From the model estimates, there is a decline of `r (1-exp(-0.04662))*100`% of the in gulls/terns/skimmers guild. While this isn't as exaggerated as the other guilds, it is still something worth noting.  

Calculate R^2 values
`r kable(r.squaredGLMM(glmernb.gulls))`

Review the residuals
```{r gull glmer resids, fig.height=8, fig.width=8, echo=FALSE}
##put all the imporant things into a data frame
resid_gulls<-data.frame(
    pearsons_residuals=resid(glmernb.gulls,type="pearson"),
    deviance_residuals=resid(glmernb.gulls,type="deviance"),
    response_residuals=guild_totals$gulls_terns-predict(glmernb.gulls,type = "response"),
    predicted=predict(glmernb.gulls,type = "response"),
    observed=guild_totals$gulls_terns)

##pgot resids and all that jazz
pr.g <- ggplot(resid_gulls,aes(x=predicted,y=pearsons_residuals)) + geom_point()
dr.g <- ggplot(resid_gulls,aes(x=predicted,y=deviance_residuals)) + geom_point()
rr.g <- ggplot(resid_gulls,aes(x=predicted,y=response_residuals)) + geom_point()
po.g <- ggplot(resid_gulls,aes(x=predicted,y=observed)) + geom_point()
grid.arrange(pr.g, dr.g, rr.g, po.g)
```

Plot the model predictions  
```{r gull mod plots, echo=FALSE}
pr.gull <- ggpredict(glmernb.gulls, c("temporada", "season"))
gg.g1 <- ggplot(pr.gull, aes(x, predicted, color=group)) + scale_color_manual(values = c("#3f2d54", "#75b8d1"))
gg.g1 + geom_point(position=pd) + geom_errorbar(aes(ymin=conf.low,ymax=conf.high), 
                                                 position=pd) + 
  scale_x_continuous(breaks = 14:20) + labs(x = "Year", y= "Predicted Count") 
```

Here we can visualize that the decline is not as steep as the other guilds, but still present. We can also once again see the notable differences between the winter and non-winter seasons. 

## Pelicans/Cormorants/Allies

Plot the data
```{r plot pel, echo=FALSE}
pel.corm1 <- ggboxplot(guild_totals, x = "temporada", y = "pel_corm",  
                   ylab = "Count", ggtheme = theme_linedraw())
pel.corm1
pel.corm2 <- ggboxplot(guild_totals, x = "temporada", y = "pel_corm", facet.by = "season", 
                   panel.labs = list(season=c("Otoño/Primavera", "Invierno")), 
                   ylab = "Count", ggtheme = theme_linedraw())
pel.corm2
```

Making the model:
```{r pel corm mod}
glmernb.pel <- glmer.nb(pel_corm ~ temporada + season + (1|obs),
                          data=guild_totals)
ss <- getME(glmernb.pel,c("theta","fixef"))
pelmod <- update(glmernb.pel,start=ss,control=glmerControl(optCtrl=list(maxfun=2e4)))
summary(pelmod)
GLMEROverdispersion(pelmod)
```
Pelicans/cormorants/allies guild is declining by `r (1-exp(-0.22764))*100`% each year. 

Calculate R^2 values
`r kable(r.squaredGLMM(pelmod))`

Plot model predictions
```{r pel mod plots, echo=FALSE}
pr.pel <- ggpredict(pelmod, c("temporada", "season"))
gg.p1 <- ggplot(pr.pel, aes(x, predicted, color=group)) + scale_color_manual(values = c("#3f2d54", "#75b8d1"))
gg.p1 + geom_point(position=pd) + geom_errorbar(aes(ymin=conf.low,ymax=conf.high), 
                                                 position=pd) + 
  scale_x_continuous(breaks = 14:20) + labs(x = "Year", y= "Predicted Count")
```
Something to note here is the axis. If you look at the boxplots above, you'll see there are two very high counts (ploted as dots aka outliers) in the 2013-2014 season. Now that can very obviously be skewing the data, but take a second to look at the axis of our graphed model predictions and you'll see that it's much smaller. 

## Long-legged Waders

**The only guild that lacks a final model**

```{r plot waderz, echo=FALSE}
waders1 <- ggboxplot(guild_totals, x = "temporada", y = "waders",
                  ylab = "Count", ggtheme = theme_linedraw())
waders1

waders2 <- ggboxplot(guild_totals, x = "temporada", y = "waders", facet.by = "season", 
                   panel.labs = list(season=c("Otoño/Primavera", "Invierno")), 
                  ylab = "Count", ggtheme = theme_linedraw())
waders2
```

```{r waders mod}
glmernb.waders <- glmer.nb(waders ~ temporada + season + (1|obs),
                          data=guild_totals)
summary(glmernb.waders)
GLMEROverdispersion(glmernb.waders)
```

***As you can see, this model failed to onverge and I haven't worked on getting a better fit yet***

## Final Table of All Models

We can put a summary of all the important parts of each model into a single table. Note that here the "estimates" of each variable have been back transformed. For example, in the shorebird model, rather than display the estimate of "-0.21397" for temporada (aka the year), the table will show the back transformed intercept (recall that for a negative binomial model we have to use the `exp()` function) so the number displayed is the incidence rate ratio of `r exp(-0.21397)`. 
This simply means that as that variable increases by 1 unit, the response variable is multipled by a factor of `r exp(-0.21397)`. 
Also note that the R^2 values displayed are calculated using the log-normal method that was shown in the tables above. 

```{r guild mods table}
tab_model(glmernb.shore1, glmernb.fowl2, glmernb.gulls, pelmod, 
          dv.labels = c("Shorebirds", "Waterfowl", "Gulls/Terns/Skimmers", 
                        "Pelicans/Cormorants/Allies"),
          string.ci = "Conf. Int (95%)", 
          string.p = "P-Value", pred.labels = c("Intercept", "Year", "Season"))
```


# Migrants and Residents?

Another important grouping to make in the bird is between the migrantory and resident species for many reasons. One interesting reason just based off the guild muilds is that when looking at the plotted model predictions, it seemed that in general, the decrease in birds over time was more pronounced in the winter season.   

```{r import mig data}
mig <- read_csv("mig_res_totals.csv", col_types = cols(Date = col_date(format = "%m/%d/%y")))

mig <- cbind(mig, a)                         ##add enviro vars
mig <- cbind(mig, mes)                       ##add month
mig <- cbind(mig, mes.yr)                    ##add year
mig <- filter(mig, szn != "4")               ##remove summer
mig$season <- ifelse(mig$szn != 2, 1, 2)     ##combine spring/fall

colnames(mig)     ##check that data combined and is complete
```

## Migrants

Start with migrants. 
Plot data:
```{r plot mig, echo=FALSE}
ggboxplot(mig, x = "temporada", y = "migrants", ylab = "# Individuals")

migrants <- ggboxplot(mig, x = "temporada", y = "migrants", facet.by = "season", 
          panel.labs = list(season=c("Otoño/Primavera", "Invierno")))
migrants
```

Make the model
```{r model}
mig.mod1 <- glmer.nb(migrants ~ temporada + season + (1|obs), data = mig)
summary(mig.mod1)
```
`r (1-exp(-0.13459))*100`% decrease over the years
`r exp(0.78086)*100`% higher in the winter
 
Plot the residuals
```{r mig glmer resids, fig.height=8, fig.width=8, echo=FALSE}
##put all the imporant things into a data frame
resid_mig<-data.frame(
    pearsons_residuals=resid(mig.mod1,type="pearson"),
    deviance_residuals=resid(mig.mod1,type="deviance"),
    response_residuals=guild_totals$gulls_terns-predict(mig.mod1,type = "response"),
    predicted=predict(mig.mod1,type = "response"),
    observed=mig$migrants)

##pgot resids and all that jazz
pr.m <- ggplot(resid_mig,aes(x=predicted,y=pearsons_residuals)) + geom_point()
dr.m <- ggplot(resid_mig,aes(x=predicted,y=deviance_residuals)) + geom_point()
rr.m <- ggplot(resid_mig,aes(x=predicted,y=response_residuals)) + geom_point()
po.m <- ggplot(resid_mig,aes(x=predicted,y=observed)) + geom_point()
grid.arrange(pr.m, dr.m, rr.m, po.m)
```

Calculate R^2 values
`r kable(r.squaredGLMM(mig.mod1))`

Plot model predictions

First we'll look at the effects of year on the model, with the other effects considereed constants. 
```{r mig mod plot, echo=FALSE}
pr.mig <- ggpredict(mig.mod1, c("temporada"))
plot(pr.mig, color="ipsum")
```

And now compare that graph to the model, but dividing out the season as we 
```{r mig mod plot pt 2, echo=FALSE}
pr.mig1 <- ggpredict(mig.mod1, c("temporada", "season"))
plot(pr.mig1, color="ipsum")       ##smoothed line

##turn into gg obj and then point/errorbar, as done with guild prediction graphs
gg.mig1 <- ggplot(pr.mig1, aes(x, predicted, color=group)) + scale_color_manual(values = c("#3f2d54", "#75b8d1"))
gg.mig1 + geom_point(position=pd) + geom_errorbar(aes(ymin=conf.low,ymax=conf.high), 
                                                 position=pd) + 
  scale_x_continuous(breaks = 14:20) + labs(x = "Year", y= "Predicted Count")
```

## Residents
*Repeat workflow*
Plot data: 
```{r plot res, echo=FALSE}
ggboxplot(mig, x = "temporada", y = "residents", ylab = "# Individuals")
residents <- ggboxplot(mig, x = "temporada", y = "residents", facet.by = "season", 
                      panel.labs = list(season=c("Otoño/Primavera", "Invierno")),
                      title = "Residents")
residents
```

Make the model

```{r res model}
res.mod1 <- glmer.nb(residents ~ temporada + season + (1|obs), data = mig)
summary(res.mod1)
```

Residents, although decreasing it's not significant. While they aren't necessarily increasing either, this means that the birds are probably fluctuating year to year but overall are not changing. This is good!!
Also, similar to all other groups, the numbers of residents increases `r exp(0.82429)*100`% in the winter months. 

Plot the residuals
```{r res glmer resids, fig.height=8, fig.width=8, echo=FALSE}
##put all the imporant things into a data frame
resid_res<-data.frame(
    pearsons_residuals=resid(res.mod1,type="pearson"),
    deviance_residuals=resid(res.mod1,type="deviance"),
    response_residuals=guild_totals$gulls_terns-predict(res.mod1,type = "response"),
    predicted=predict(res.mod1,type = "response"),
    observed=mig$residents)

##pgot resids and all that jazz
pr.r <- ggplot(resid_res,aes(x=predicted,y=pearsons_residuals)) + geom_point()
dr.r <- ggplot(resid_res,aes(x=predicted,y=deviance_residuals)) + geom_point()
rr.r <- ggplot(resid_res,aes(x=predicted,y=response_residuals)) + geom_point()
po.r <- ggplot(resid_res,aes(x=predicted,y=observed)) + geom_point()
grid.arrange(pr.r, dr.r, rr.r, po.r)
```

Calculate R^2 values
`r kable(r.squaredGLMM(res.mod1))`

Plot model predictions
```{r res mod plots, echo=FALSE}
pr.res <- ggpredict(res.mod1, c("temporada", "season"))
plot(pr.res, color="ipsum")
gg.res1 <- ggplot(pr.res, aes(x, predicted, color=group)) + scale_color_manual(values = c("#3f2d54", "#75b8d1"))
gg.res1 + geom_point(position=pd) + geom_errorbar(aes(ymin=conf.low,ymax=conf.high), 
                                                 position=pd) + 
  scale_x_continuous(breaks = 14:20) + labs(x = "Year", y= "Predicted Count") 
```
As we can see in the model prediction graphs above- our confidence intervals are very large. And though the trend is a decrease over time, there is not a lot to support that statement. So in looking at these graphs, we can see how much overlap there is in the points and confidence intervals.


## Final Table of Mig Models

Repeating what we did, we can create a model summary table for our two. And once again, what were the intercepts of the model have been back transformed into incidence rate ratios. 

```{r mig/res mods table}
tab_model(mig.mod1, res.mod1, 
          dv.labels = c("Migrants", "Residents"),
          string.ci = "Conf. Int (95%)", 
          string.p = "P-Value", pred.labels = c("Intercept", "Year", "Season"))
```

This is a clean way to summarize some stuff.

## Some Thoughts

Given that most of the guilds seem to be trending downward. Let's take a look once again at the predicted values of the models for each guild. In each of the models, the starting point was much higher in the winter and seemingly decreased more notably.

```{r all plots together, echo=FALSE}
gr1 <- ggplotGrob(plot(pr1, show.title=FALSE, show.legend=TRUE, color="ipsum"))
gr2 <- ggplotGrob(plot(pr.fowl, show.title=FALSE, show.legend=FALSE, color="ipsum"))
gr3 <- ggplotGrob(plot(pr.gull, show.title=FALSE, show.legend=TRUE, color="ipsum"))
gr4 <- ggplotGrob(plot(pr.pel, show.title=FALSE, show.legend=FALSE, color="ipsum"))

grid.arrange(gr1, gr2, gr3, gr4, 
             layout_matrix = rbind(c(1,1,1,1,1,1,2,2,2,2,2),
                                   c(3,3,3,3,3,3,4,4,4,4,4)))
```

One reason I had moved from working with biodiversity indices to  working on this modeling project was because it was clear that important aspect of the survey data was missing. For the calculating the biodiversity indices for example, birds had to be identified to species. This completely glosses over the impact of larger aggregations of birds that are identified to a group but not necessarily species (ie estimations of "1000 peeps"). In separting the birds into guilds, this important aspect of data that can be captured. 

```{r mig res mod plots, fig.height=8, fig.width=7}
gm1 <- ggplotGrob(plot(pr.mig1, show.title=FALSE, show.legend=TRUE, color="ipsum"))
gre1 <- ggplotGrob(plot(pr.res, show.title=FALSE, show.legend=TRUE, color="ipsum"))
grid.arrange(gm1, gre1)
```

So in looking at our model, it doesn't seem as if residents are changing but migrants are. This might suggest that the overall declines across the bird guilds are unequally attributed to declines in migrants overwintering. This could be a big jump to make, but it's something that seemingly makes sense. 
BUT ALSO with the separation between migrant/resident spp, I did not include these unidentified birds. Despite this, we still saw some interesting changes and that migrants are following these trends to be declinging. 

But finally, a big thing to keep in mind is that there is a lot of variability in all our data over time **so all results should be taken with a grain of salt.**

# Future Directions

While this was fun, the work isn't done. For example, there are several other cool questions that can be answered. Part of the problem is the surveys lack a consistent protocol. For example, I do now know how people in 2015 measured the tide or temperature. Gathering better data on historic weather/climate conditions would be interesting to look at changes or potential correlations between temp and bird relative abundances. Though we take data on the temperature during each monitoring effort, examining climate from a wider lens would be interesting. Precipitation patterns or extreme temperature events could potentially be affecting the phenology of migration in some birds that may be using temp/precip patterns as environmental cues. While some temperature and precipitation data are available [here](http://clicom-mex.cicese.mx/mapa.html), I found the data in the area to be incomplete and lacking the last few years. 
Another interesting direction would be to relate the abundances of shorebirds (and/or other guilds) to tides. While we take data on the tides, it would be possible to more accurately characterize the tide.
